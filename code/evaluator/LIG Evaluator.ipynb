{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "964ded50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import confusion_matrix, classification_report,f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import heapq\n",
    "from collections import Counter\n",
    "import os\n",
    "import ast\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import lime\n",
    "random.seed(1993)\n",
    "random.seed(1993)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "652dfaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Evanukachum pondati kolandhainu sentiment irun...</td>\n",
       "      <td>[71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adei ennada short film la irunthu suturukinga</td>\n",
       "      <td>[34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Super dialogue  Oruthar mela visvasam kattrath...</td>\n",
       "      <td>[68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Epadiya jathi padam. Ponnu padama edungada. In...</td>\n",
       "      <td>[67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ponnu mella kaivaikuravan Kai mattum illa uyir...</td>\n",
       "      <td>[42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>காலா.காபலி.அசுரன்.பாரியேரும்.பெருமள் வந்த அப்ப...</td>\n",
       "      <td>[101, 102, 103, 104, 105, 106, 107, 108, 109, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>Kekka bekka short film mathri irukey</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>Bayangaram... Trailerey ippadina appa Padam en...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>komali rasini vesam pottu tamil ilichavayangal...</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 31, 32, 33, 34, 35, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>Oruththar Mela katra viswasaththukku maththava...</td>\n",
       "      <td>[56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>876 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    Evanukachum pondati kolandhainu sentiment irun...   \n",
       "1        Adei ennada short film la irunthu suturukinga   \n",
       "2    Super dialogue  Oruthar mela visvasam kattrath...   \n",
       "3    Epadiya jathi padam. Ponnu padama edungada. In...   \n",
       "4    Ponnu mella kaivaikuravan Kai mattum illa uyir...   \n",
       "..                                                 ...   \n",
       "871  காலா.காபலி.அசுரன்.பாரியேரும்.பெருமள் வந்த அப்ப...   \n",
       "872               Kekka bekka short film mathri irukey   \n",
       "873  Bayangaram... Trailerey ippadina appa Padam en...   \n",
       "874  komali rasini vesam pottu tamil ilichavayangal...   \n",
       "875  Oruththar Mela katra viswasaththukku maththava...   \n",
       "\n",
       "                                                 spans  \n",
       "0    [71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 8...  \n",
       "1     [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]  \n",
       "2    [68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 7...  \n",
       "3    [67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 7...  \n",
       "4    [42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 5...  \n",
       "..                                                 ...  \n",
       "871  [101, 102, 103, 104, 105, 106, 107, 108, 109, ...  \n",
       "872             [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]  \n",
       "873                 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  \n",
       "874  [0, 1, 2, 3, 4, 5, 6, 7, 31, 32, 33, 34, 35, 3...  \n",
       "875  [56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 6...  \n",
       "\n",
       "[876 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../data/span/test/test.tsv\",sep=\"\\t\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "026fad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex + Multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abb22910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the output and create spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f661b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_span(predictions, gold):\n",
    "    \"\"\"\n",
    "    F1 (a.k.a. DICE) operating on two lists of offsets (e.g., character).\n",
    "    >>> assert f1([0, 1, 4, 5], [0, 1, 6]) == 0.5714285714285714\n",
    "    :param predictions: a list of predicted offsets\n",
    "    :param gold: a list of offsets serving as the ground truth\n",
    "    :return: a score between 0 and 1\n",
    "    \"\"\"\n",
    "    if len(gold) == 0:\n",
    "        if len(predictions) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    if len(predictions) == 0:\n",
    "        return 0.\n",
    "    predictions_set = set(predictions)\n",
    "    gold_set = set(gold)\n",
    "    nom = 2 * len(predictions_set.intersection(gold_set))\n",
    "    denom = len(predictions_set) + len(gold_set)\n",
    "    return float(nom)/float(denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30cda66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex-Multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9b23b101",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 0.42067713023396935\n",
      "Results: 0.4926620524160055\n",
      "Results: 0.47332544655541625\n",
      "Results: 0.3974326328958221\n"
     ]
    }
   ],
   "source": [
    "#BERT ONLY\n",
    "\n",
    "import re\n",
    "\n",
    "def eval_multiple(LIMEFILE,MAXSIZE,MINSIZE):\n",
    "    \n",
    "    output_xlm_cm = np.load(LIMEFILE,allow_pickle=True)\n",
    "    new_output_xlm=[]\n",
    "    df_test = pd.read_csv(\"../data/span/test/test.tsv\",sep=\"\\t\")\n",
    "    \n",
    "    start=0\n",
    "    full_res=[]\n",
    "    for index in range(len(output_xlm_cm)):\n",
    "        modified=[]\n",
    "        temp = output_xlm_cm[index][\"LABEL_0\"][1:-1]\n",
    "        start=0\n",
    "        for w,s in temp:\n",
    "            if \"##\" in w:\n",
    "                modified.append((w,s,[i for i in range(start,start+len(w)-2)]))\n",
    "                start+=len(w)-2\n",
    "            elif \"_\" in w:\n",
    "                modified.append((w,s,[i for i in range(start,start+len(w)-1)]))\n",
    "                start+=len(w)-1\n",
    "            else:\n",
    "                modified.append((w,s,[i for i in range(start,start+len(w))]))\n",
    "                start+=len(w)\n",
    "        full_res.append(modified)\n",
    "    \n",
    "    THRESH=-200\n",
    "    \n",
    "    totalscore=[]\n",
    "    for index in range(len(full_res)):\n",
    "        if len(df_test[\"text\"].values.tolist()[index])>=MINSIZE and len(df_test[\"text\"].values.tolist()[index])<=MAXSIZE:\n",
    "            gt = df_test[\"spans\"].values.tolist()[index]\n",
    "            predspan=[]\n",
    "            for word,score,sp in full_res[index]:\n",
    "                if score>=THRESH:\n",
    "                    predspan+=sp\n",
    "            sc = f1_span(predspan, ast.literal_eval(gt))\n",
    "            totalscore.append(sc)\n",
    "    \n",
    "    print(\"Results:\",np.average(totalscore))\n",
    "    \n",
    "LIMEFILE = \"../models/complex_cue_multi/offensive_xlm_complex_aug_multi/xlm_roberta_attribution_complex_multi_all.npy\"\n",
    "\n",
    "MAXSIZE = 10000\n",
    "MINSIZE = 0\n",
    "eval_multiple(LIMEFILE,MAXSIZE,MINSIZE)\n",
    "\n",
    "MAXSIZE = 30\n",
    "MINSIZE = 0\n",
    "eval_multiple(LIMEFILE,MAXSIZE,MINSIZE)\n",
    "\n",
    "MAXSIZE = 50\n",
    "MINSIZE = 30\n",
    "eval_multiple(LIMEFILE,MAXSIZE,MINSIZE)\n",
    "\n",
    "MAXSIZE = 500\n",
    "MINSIZE = 50\n",
    "eval_multiple(LIMEFILE,MAXSIZE,MINSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ce8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline and Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5af8248",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lime_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9616\\576527463.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[0mMAXSIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mMINSIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m \u001b[0meval_multiple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLIMEFILE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mMAXSIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mMINSIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;31m# MAXSIZE = 50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9616\\576527463.py\u001b[0m in \u001b[0;36meval_multiple\u001b[1;34m(LIMEFILE, MAXSIZE, MINSIZE)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_span\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredspan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlime_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mtotalscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lime_pred' is not defined"
     ]
    }
   ],
   "source": [
    "#BERT ONLY\n",
    "\n",
    "import re\n",
    "\n",
    "def eval_multiple(LIMEFILE,MAXSIZE,MINSIZE):\n",
    "    \n",
    "    output_xlm_cm = np.load(LIMEFILE,allow_pickle=True)\n",
    "    new_output_xlm=[]\n",
    "    df_test = pd.read_csv(\"../data/span/test/test.tsv\",sep=\"\\t\")\n",
    "    \n",
    "    start=0\n",
    "    full_res=[]\n",
    "    for index in range(len(output_xlm_cm)):\n",
    "        modified=[]\n",
    "        \n",
    "        temp = output_xlm_cm[index][1:-1]\n",
    "        start=0\n",
    "        for w,s in temp:\n",
    "            if \"##\" in w:\n",
    "                modified.append((w,s,[i for i in range(start,start+len(w)-2)]))\n",
    "                start+=len(w)-2\n",
    "            elif \"_\" in w:\n",
    "                modified.append((w,s,[i for i in range(start,start+len(w)-1)]))\n",
    "                start+=len(w)-1\n",
    "            else:\n",
    "                modified.append((w,s,[i for i in range(start,start+len(w))]))\n",
    "                start+=len(w)\n",
    "        full_res.append(modified)\n",
    "    \n",
    "    THRESH=-100\n",
    "    \n",
    "    totalscore=[]\n",
    "    for index in range(len(full_res)):\n",
    "        if len(df_test[\"text\"].values.tolist()[index])>=MINSIZE and len(df_test[\"text\"].values.tolist()[index])<=MAXSIZE:\n",
    "            gt = df_test[\"spans\"].values.tolist()[index]\n",
    "            predspan=[]\n",
    "            for word,score,sp in full_res[index]:\n",
    "                if score>=THRESH:\n",
    "                    predspan+=sp\n",
    "            sc = f1_span(predspan, ast.literal_eval(gt))\n",
    "\n",
    "            \n",
    "            totalscore.append(sc)\n",
    "    \n",
    "    print(\"Results:\",np.average(totalscore))\n",
    "    \n",
    "LIMEFILE = \"../models/baseline/offensive_xlm_baseline/xlm_roberta_attribution_baseline.npy\"\n",
    "\n",
    "# MAXSIZE = 10000\n",
    "# MINSIZE = 0\n",
    "# eval_multiple(LIMEFILE,MAXSIZE,MINSIZE)\n",
    "\n",
    "MAXSIZE = 1000\n",
    "MINSIZE = 0\n",
    "eval_multiple(LIMEFILE,MAXSIZE,MINSIZE)\n",
    "\n",
    "# MAXSIZE = 50\n",
    "# MINSIZE = 30\n",
    "# eval_multiple(LIMEFILE,MAXSIZE,MINSIZE)\n",
    "\n",
    "# MAXSIZE = 500\n",
    "# MINSIZE = 50\n",
    "# eval_multiple(LIMEFILE,MAXSIZE,MINSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb83d336",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
